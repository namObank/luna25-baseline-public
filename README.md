üì¶ LUNA25 Baseline Algorithm

1. Prepare environment and test the code

Install python 3.10

Note: first, copy the resource folder containing *pth files into this repo

Install packages

```bash
pip install -r requirements.txt
```

To test the code, run server directly from source
```bash
uvicorn server:app --reload
```
Alternatively
```bash
uvicorn server:app --reload --host 0.0.0.0 --port 8000
```

Import cURL in postman to send request (remember to include mha file in the request)
```bash
curl --location 'localhost:8000/api/v1/predict/lesion' \
--form 'file=@"/D:/luna_data/luna25_images_sample/1.3.6.1.4.1.14519.5.2.1.7009.9004.302654768337221344067573753621.mha"' \
--form 'seriesInstanceUID="1.3.6.1.4.1.14519.5.2.1.7009.9004.302654768337221344067573753621"' \
--form 'patientID="212849"' \
--form 'studyDate="20000102"' \
--form 'lesionID="2"' \
--form 'coordX="108.05"' \
--form 'coordY="67.82"' \
--form 'coordZ="-227.01"' \
--form 'ageAtStudyDate="72"' \
--form 'gender="Female"'
```

2. Containerizing 

Packaging
```bash
docker build -t <image_name> .
```

Running (specify your port as needed)
```bash
docker run -it --rm -p 8000:8000 <image_name>
```

D∆∞·ªõi ƒë√¢y l√† m·ªôt m·∫´u **README** m√† √¥ng c√≥ th·ªÉ d√πng cho project FastAPI, h∆∞·ªõng d·∫´n t·ª´ c√†i ƒë·∫∑t m√¥i tr∆∞·ªùng Conda, Linux, Python 3.10, ƒë·∫øn build v√† ch·∫°y Docker cho m·ª•c ƒë√≠ch inference:

---

# Project Name

M·ª•c ti√™u: Tri·ªÉn khai FastAPI ƒë·ªÉ ph·ª•c v·ª• **inference** m√¥ h√¨nh.

## 1. Y√™u c·∫ßu h·ªá th·ªëng

* H·ªá ƒëi·ªÅu h√†nh: Linux (Ubuntu 20.04+ khuy·∫øn ngh·ªã)
* Python: 3.10
* Conda: >= 4.10
* Docker & Docker Compose: >= 20

---

## 2. C√†i ƒë·∫∑t m√¥i tr∆∞·ªùng Conda

1. T·∫°o m√¥i tr∆∞·ªùng Conda v·ªõi Python 3.10:

```bash
conda create -n myenv python=3.10 -y
```

2. K√≠ch ho·∫°t m√¥i tr∆∞·ªùng:

```bash
conda activate myenv
```

3. C√†i ƒë·∫∑t c√°c dependencies:

```bash
pip install -r requirements.txt
```

> Ghi ch√∫: `requirements.txt` n√™n ch·ª©a c√°c th∆∞ vi·ªán nh∆∞ `fastapi`, `uvicorn`, v√† c√°c th∆∞ vi·ªán inference c·ªßa m√¥ h√¨nh b·∫°n.

---

## 3. Ch·∫°y server FastAPI

Trong m√¥i tr∆∞·ªùng Conda ƒë√£ k√≠ch ho·∫°t:

```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

* `app.main:app` l√† ƒë∆∞·ªùng d·∫´n t·ªõi `FastAPI()` instance trong project c·ªßa √¥ng.
* M·ªü tr√¨nh duy·ªát ho·∫∑c postman truy c·∫≠p: `http://localhost:8000/docs` ƒë·ªÉ xem API docs.

---

## 4. Ch·∫°y inference tr·ª±c ti·∫øp

V√≠ d·ª• g·ªçi API `POST /predict`:

```bash
curl -X POST "http://localhost:8000/predict" -H "Content-Type: application/json" -d '{"input": "your input data"}'
```

---

## 5. Build Docker Image

1. T·∫°o file `Dockerfile` v√≠ d·ª•:

```dockerfile
# Dockerfile
FROM python:3.10-slim

WORKDIR /app

# Copy requirements v√† c√†i ƒë·∫∑t
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy code
COPY . .

# Expose port
EXPOSE 8000

# L·ªánh ch·∫°y server
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

2. Build Docker image:

```bash
docker build -t fastapi-inference:latest .
```

3. Ch·∫°y Docker container:

```bash
docker run -d -p 8000:8000 fastapi-inference:latest
```

* Truy c·∫≠p: `http://localhost:8000/docs`

---

## 6. Optional: Docker Compose

T·∫°o `docker-compose.yml`:

```yaml
version: "3.9"

services:
  fastapi-app:
    build: .
    ports:
      - "8000:8000"
    environment:
      - PYTHONUNBUFFERED=1
```

Ch·∫°y:

```bash
docker-compose up --build
```

---

## 7. K·∫øt lu·∫≠n

* M√¥i tr∆∞·ªùng Conda gi√∫p qu·∫£n l√Ω Python 3.10 v√† dependencies.
* Docker gi√∫p deploy nhanh v√† nh·∫•t qu√°n tr√™n Linux server.
* Server FastAPI s·∫µn s√†ng ph·ª•c v·ª• **inference** th√¥ng qua API endpoint.

---

N·∫øu mu·ªën, t√¥i c√≥ th·ªÉ vi·∫øt lu√¥n **phi√™n b·∫£n README t·ªëi gi·∫£n, chu·∫©n c√¥ng ty**, v·ª´a d·ªÖ copy, v·ª´a ƒë·ªß ch·∫°y inference tr√™n Docker m√† kh√¥ng c·∫ßn nhi·ªÅu gi·∫£i th√≠ch. √îng c√≥ mu·ªën t√¥i l√†m lu√¥n kh√¥ng?


<!-- # üì¶ LUNA25 Baseline Algorithm
Thank you for participating in the [LUNA25 Challenge](https://luna25.grand-challenge.org/).

In LUNA25, we want to use artificial intelligence for lung nodule malignancy risk estimation on low-dose chest CT scans. For this, we have prepared two baseline models (2D and 3D model) that can help you get started. 

The development of your algorithms should be performed using your local GPU or a cloud platform (such as AWS or Azure), while algorithm evaluation will be performed exclusively on the [Grand-Challenge](https://grand-challenge.org/) platform.

## üóÇÔ∏è Content
This baseline algorithm provides a framework for training and testing models. While it includes basic scripts, we encourage you to extend and customize them to develop alternative or improved methods.

Important Files:
- ü¶æ `train.py`: A script for training the baseline algorithm on local data.
- ü¶ø `inference.py`: A script for testing the trained algorithm using a specified configuration.
- üßÆ `Dockerfile`: A file to build a Docker container for deployment on Grand-Challenge. For help on setting up Docker with GPU support you can check the documentation on [Grand-Challenge](https://grand-challenge.org/documentation/setting-up-wsl-with-gpu-support-for-windows-11/) or [Docker](https://docs.docker.com/engine/install/ubuntu/) for additional information.

## ‚öôÔ∏è Setting up the Environment
To set up the required environment for the baseline algorithm:
1. **Create an environment and esure Python is Installed**: Install Python 3.9 or higher:
    ```bash
    conda create -n luna25-baseline python==3.9
    ```
2. **Install Dependencies**:
    - Run the following command to install the dependencies listed in `requirements.txt`:
    ```bash
    pip install -r requirements.txt
    ```
3. **Verify Installation**:
    - Test the installation by running:
    ```bash
    python --version
    pip list
    ```
    Ensure all required packages are listed and no errors are reported.

## üöÄ Performing a Training Run
1. **Set up training configurations**

Open `experiment_config.py` to edit your training configurations. Key parameters include:

- `self.MODE`: Set this to 2D or 3D depending on the desired baseline model.
- `self.EXPERIMENT_NAME`: Specify the name of your experiment (e.g. LUNA25-baseline).
- `self.CSV_DIR_TRAIN`: the path to the training csv file
- `self.DATADIR`: the path where the images are stored


2. **Training the Model**

To train the model using the `train.py` script:
```bash
python train.py
```
This script uses the settings from experiment_config.py to initialize and train the model.

## üß™ Testing the Trained Algorithm
1. **Configure the inference script**

Open the `inference.py` script and configure:
- `INPUT_PATH`: Path to the input data (CT, nodule locations and clinical information). Keep as `Path("/input")` for Grand-Challenge.
- `RESOUCE_PATH`: Path to resources (e.g., pretrained models weights) in the container. Defaults to `/results` directory (see Dockerfile)
- `OUTPUT_PATH`: Path to store the output in your local directory. Keep as `Path("/output")` for Grand-Challenge.
- **Inputs for the `run()` function**:
    - `mode`: Match this to the mode used during training (2D or 3D).
    - `model_name`: Specify the experiment_name matching the training configuration (corresponding to experiment_name directory that contains the model weights in `/results`).

2. **Updating the Docker Image Tag**

In `do_test_run.sh`, update the Docker image tag as needed:
```bash
DOCKER_IMAGE_TAG="luna25-baseline-3d-algorithm-open-development-phase"
```


3. **Running the Test Script**

To test the trained model for running inference run: 
```bash
./do_test_run.sh
``` 

This script performs the following:
- Uses Docker to execute the `inference.py` script.
- Mounts necessary input and output directories.
- Adjusts the Docker image tag (if updated) before running.

## üê≥ Building the Docker Image
To build the Docker container required for submission to Grand-Challenge run:
```bash
./do_save.sh
```
This will output a *.tar.gz file, which can be uploaded to Grand-Challenge.
More information on testing and deploying your container can be found [here](https://grand-challenge.org/documentation/test-and-deploy-your-container/).

## üõ†Ô∏è Extending the Baseline
While this baseline provides a starting point, participants are encouraged to:

- Implement advanced AI models.
- Explore alternative data preprocessing and augmentation techniques.
- perform Ensemble Learning
- train models using entire or larger CT scan inputs

For questions, refer to the [LUNA25 Challenge Page](https://luna25.grand-challenge.org/).

Good luck! -->